# -*- coding: utf-8 -*-
"""Flipkart Customer Satisfaction Analysis and Prediction (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VwaF6JpODCgCBff3X98JB0cVNaZPxS9A

## 1.  Project Title, Problem Statement & Objective

**Title**: Flipkart Customer Satisfaction Analysis and Prediction

**Problem Statement**:

In the competitive e-commerce landscape, customer satisfaction plays a crucial role in both customer retention and brand loyalty. Flipkart, as one of India's largest online retail platforms, receives a high volume of customer service interactions across multiple channels, including chat, call, and email.

The company seeks to understand the key drivers of customer satisfaction by analyzing customer feedback, issue categories, agent performance, and support channel effectiveness. Additionally, Flipkart aims to proactively identify dissatisfied customers using predictive analytics to improve service quality and reduce churn.

This project addresses the need to:
- Analyze historical customer support data to uncover patterns and pain points.
- Use sentiment analysis to evaluate customer remarks.
- Build a machine learning model to predict low satisfaction cases.
- Generate actionable recommendations for improving customer support operations.

**Objective**:  
The objective of this project is to analyze customer support interactions at Flipkart to identify the key factors influencing customer satisfaction (CSAT). The project aims to uncover insights through exploratory data analysis, sentiment analysis of customer feedback, and predictive modeling. These insights will help improve agent performance, optimize support channels, and proactively address customer concerns to enhance overall satisfaction and brand  lty.

---

## 2. Dataset Description

The dataset contains records of customer support interactions from Flipkart, including CSAT scores, feedback text, order and issue details, agent and manager names, product categories, prices, and timestamps.  

**Dataset Summary**:
- Total records: 85,907
- Total columns: 20
- Target column: CSAT Score (1 to 5)
- Features include: support channel, issue category, customer remarks, agent name, shift, tenu item price, etc.

---

## 3. Data Cleaning

Several steps were taken to clean the dataset:
- Removed columns with excessive missing values (e.g., `connected_handling_time`, `order_date_time`)
- Dropped rows with missing customer remarks where needed for sentiment analysis
- Checked for and handled missing values in fields like `Item_price`, `Product_category`, `Customer_City`
- Converted categorical variables for modeling using one-hot encoding
- Created a binary target variable for classification: Low Satisfaction (CSAT ≤ 3) vs High Satisfaction (CSAT > 3)
 ≤ 3) vs High Satisfaction (CSAT > 3)
y.
"""

# pip install wordcloud
# pip install textblob

# Commented out IPython magic to ensure Python compatibility.
# Data Handling
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

# Text Analysis
from wordcloud import WordCloud
from textblob import TextBlob

# Machine Learning Tools (for later)
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Warnings
import warnings
warnings.filterwarnings('ignore')

# Load the dataset
df = pd.read_csv("Customer_support_data.csv")

# Show the first few rows
df.head()

# Check structure of dataset
df.info()

# Check for missing values
df.isnull().sum()

# Basic statistical summary
df.describe()

# Check all current column names
df.columns.tolist()

# Check missing values
missing = df.isnull().sum().sort_values(ascending=False)
missing[missing > 0]

# Drop very sparse columns
df.drop(columns=['connected_handling_time', 'order_date_time'], inplace=True)

# Optional: drop rows where Customer Remarks is missing (for text/sentiment analysis)
df_text = df.dropna(subset=['Customer Remarks'])

# Show new shape of text-based DataFrame
df_text.shape

"""## Exploratory Data Analysis (EDA)

The goal of EDA is to uncover patterns, trends, and anomalies in the Flipkart customer support data to understand what drives customer satisfaction (CSAT). Below are the key insights discovered:

### CSAT Score Distribution
- Most customers rate their experience with a score of 4 or 5, indicating generally high satisfaction.
- A smaller segment of customers gave scores of 1 to 3, representing potential dissatisfaction.

### CSAT by Support Channel
- Support channels like Chat and Call show different levels of satisfaction.
- Some channels consistently deliver higher CSAT than others, indicating variation in experience quality.

### CSAT by Issue Category
- Certain issue categories such as Returns, Delivery Delays, and Product Issues showed lower average CSAT scores.
- These categories highlight the most critical pain points in the customer journey.

### Agent Performance Analysis
- Agent-wise average CSAT reveals significant performance differences.
- The bottom 10 agents consistently receive low CSAT scores, suggesting a need for targeted training.
- The top 10 agents perform exceptionally well, indicating best practices that can be shared.

### CSAT vs Item Price
- A scatter plot between item price and CSAT reveals no strong correlation.
- Customers appear to care more about service quality than product price when rating satisfaction.

These insights were visualized using Seaborn and Matplotlib, including countplots, boxplots, bar charts, and scatter plots.
harts, and scatter plots.

"""

# 4. Exploratory Data Analysis (EDA)

import matplotlib.pyplot as plt
import seaborn as sns

# Set style
sns.set(style="whitegrid")

# A. CSAT Score Distribution
plt.figure(figsize=(8,5))
sns.countplot(x='CSAT Score', data=df, palette='viridis')
plt.title('Distribution of Customer Satisfaction (CSAT) Scores')
plt.xlabel('CSAT Score (1 = Low, 5 = High)')
plt.ylabel('Number of Customers')
plt.show()

# B. CSAT Score by Channel
plt.figure(figsize=(10,6))
sns.boxplot(x='channel_name', y='CSAT Score', data=df)
plt.title('CSAT Score by Support Channel')
plt.xlabel('Channel')
plt.ylabel('CSAT Score')
plt.xticks(rotation=45)
plt.show()

# C. CSAT Score by Category (Top 10 Categories)
top_categories = df['category'].value_counts().nlargest(10).index

plt.figure(figsize=(12,6))
sns.boxplot(x='category', y='CSAT Score', data=df[df['category'].isin(top_categories)])
plt.title('CSAT Scores by Top 10 Issue Categories')
plt.xlabel('Category')
plt.ylabel('CSAT Score')
plt.xticks(rotation=45)
plt.show()

# D. Agent Performance - Bottom 10 Agents
agent_scores = df.groupby('Agent_name')['CSAT Score'].mean().sort_values()

plt.figure(figsize=(10,5))
agent_scores.head(10).plot(kind='barh', color='salmon')
plt.title('Bottom 10 Performing Agents (Avg CSAT)')
plt.xlabel('Average CSAT Score')
plt.ylabel('Agent')
plt.show()

# E. Agent Performance - Top 10 Agents
plt.figure(figsize=(10,5))
agent_scores.tail(10).plot(kind='barh', color='seagreen')
plt.title('Top 10 Performing Agents (Avg CSAT)')
plt.xlabel('Average CSAT Score')
plt.ylabel('Agent')
plt.show()

# F. CSAT Score vs Item Price
plt.figure(figsize=(8,5))
sns.scatterplot(x='Item_price', y='CSAT Score', data=df)
plt.title('Item Price vs CSAT Score')
plt.xlabel('Item Price')
plt.ylabel('CSAT Score')
plt.show()

"""## Sentiment Analysis Summary

To better understand customer emotions and how they relate to satisfaction scores, sentiment analysis was performed on the free-text feedback in the `Customer Remarks` column using TextBlob.

Key Steps:
- Cleaned and filtered rows with non-null customer remarks.
- Calculated sentiment polarity for each remark (ranging from -1 to 1).
- Visualized sentiment polarity distribution.
- Plotted sentiment polarity vs CSAT Score to observe correlations.
- Generated WordClouds to highlight common keywords in both negative and positive feedback.

Observations:
- Negative sentiment remarks generally correlated with low CSAT scores (1–3).
- Positive sentiment remarks aligned with high CSAT scores (4–5).
- Frequent negative terms indicated issues like delays, returns, or poor agent interaction.

"""

# Create a new DataFrame with only non-null remarks
df_text = df.dropna(subset=['Customer Remarks'])

# Check the shape
df_text.shape

# Basic Sentiment Score Using TextBlob
from textblob import TextBlob

# Function to get sentiment polarity
df_text['Sentiment_Polarity'] = df_text['Customer Remarks'].apply(lambda x: TextBlob(x).sentiment.polarity)

# Check distribution
df_text['Sentiment_Polarity'].hist(bins=50, figsize=(8,5), color='skyblue')
plt.title('Distribution of Sentiment Polarity from Customer Remarks')
plt.xlabel('Polarity Score (-1 = Negative, +1 = Positive)')
plt.ylabel('Count')
plt.show()

#Correlation Between Sentiment and CSAT Score
plt.figure(figsize=(8,5))
sns.boxplot(x='CSAT Score', y='Sentiment_Polarity', data=df_text)
plt.title('Customer Sentiment vs CSAT Score')
plt.show()

#WordCloud of Negative & Positive Feedback
from wordcloud import WordCloud

# Negative feedback only
negative_feedback = ' '.join(df_text[df_text['Sentiment_Polarity'] < 0]['Customer Remarks'].dropna())
positive_feedback = ' '.join(df_text[df_text['Sentiment_Polarity'] > 0]['Customer Remarks'].dropna())

# WordClouds
wordcloud_neg = WordCloud(width=800, height=400, background_color='white').generate(negative_feedback)
wordcloud_pos = WordCloud(width=800, height=400, background_color='white').generate(positive_feedback)

# Plot
plt.figure(figsize=(16, 6))

plt.subplot(1, 2, 1)
plt.imshow(wordcloud_neg, interpolation='bilinear')
plt.axis('off')
plt.title('Negative Feedback WordCloud')

plt.subplot(1, 2, 2)
plt.imshow(wordcloud_pos, interpolation='bilinear')
plt.axis('off')
plt.title('Positive Feedback WordCloud')

plt.show()

"""## Predictive Modeling Summary

The goal was to build a classification model to predict whether a customer would give a low CSAT score (1 to 3) based on interaction features.

Key Steps:
- Created a binary target variable: Low Satisfaction (1) vs High Satisfaction (0).
- Selected categorical features such as channel, category, agent shift, tenure, and agent name.
- Applied one-hot encoding to categorical variables.
- Split data into training and testing sets (80/20).
- Trained two models:  
  - Random Forest Classifier  
  - Decision Tree Classifier

Evaluation:
- Used accuracy, confusion matrix, and classification report for evaluation.
- Random Forest Accuracy: 68% 
- Decision Tree Accuracy: 73%
- Feature importance was extracted from the Random Forest model.

These models allow the business to proactively flag potentially unsatisfied customers based on their interaction details.
time.

"""

# Create binary CSAT: 1 = Low, 0 = High
df['Low_Satisfaction'] = df['CSAT Score'].apply(lambda x: 1 if x <= 3 else 0)

# Check distribution
df['Low_Satisfaction'].value_counts()

# Select features
features = ['channel_name', 'category', 'Agent_name', 'Tenure Bucket', 'Agent Shift']
X = df[features]
y = df['Low_Satisfaction']

# One-hot encoding for categorical features
X_encoded = pd.get_dummies(X, drop_first=True)
X_encoded.shape

X_encoded.dtypes

# Ensure all columns are numeric
X_encoded = X_encoded.apply(pd.to_numeric, errors='coerce')

# Drop any rows with NaNs just in case
X_encoded = X_encoded.dropna()
y = y[X_encoded.index]  # Align target

# Convert boolean columns to integers
X_encoded = X_encoded.astype(int)

# Then retry SMOTE
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_bal, y_bal = smote.fit_resample(X_encoded, y)

from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# 1. Prepare balanced data
smote = SMOTE(random_state=42)
X_bal, y_bal = smote.fit_resample(X_encoded, y)

# 2. Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.2, random_state=42)

# 3. Train Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Predict probabilities
y_proba = rf.predict_proba(X_test)[:, 1]

# Apply threshold
threshold = 0.3
y_pred = (y_proba >= threshold).astype(int)

# Evaluate
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print(f"\nModel Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%")

#Train the model using Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Train the Decision Tree Classifier
tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, y_train)

# Make predictions
y_tree_pred = tree_model.predict(X_test)

# Evaluation
print(" Decision Tree Classifier Results")
print("Confusion Matrix:\n", confusion_matrix(y_test, y_tree_pred))
print("Classification Report:\n", classification_report(y_test, y_tree_pred))

# Accuracy
tree_accuracy = accuracy_score(y_test, y_tree_pred)
print(f"Decision Tree Accuracy: {tree_accuracy:.2%}")

#comparison plot
models = {
    "Random Forest": accuracy_score(y_test, y_pred),
    "Decision Tree": accuracy_score(y_test, y_tree_pred)
}

plt.figure(figsize=(6, 4))
sns.barplot(x=list(models.keys()), y=list(models.values()), palette='Set2')
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.ylim(0, 1)
plt.show()

"""**UI Interface Summary**


The Flipkart Customer Satisfaction project features a Streamlit-based UI interface designed for interactive data analysis and prediction. It consists of three main functional sections organized into tabs:



**1. Exploratory Data Analysis (EDA)**
This tab helps users explore key patterns in the data through interactive visualizations. It includes:

Distribution of CSAT (Customer Satisfaction) scores

CSAT scores across different support channels

Performance comparison among top and bottom agents

Issue category analysis

Relationship between item price and CSAT



**2. Sentiment Analysis**
This tab analyzes customer remarks using NLP:

Calculates sentiment polarity (positive/negative)

Displays distribution of sentiments

Analyzes the relationship between sentiment and CSAT scores

Summarizes feedback using text-based WordClouds (in code, not shown in this summary)



**3. Prediction Tool**
This tab allows users to input customer service scenario details and get a predicted satisfaction result. Key inputs include:

Support channel

Issue category

Agent name

Tenure bucket

Agent shift

Users can choose between two models:

Random Forest

Decision Tree

The app uses these inputs to predict if a customer will have high or low satisfaction.
"""

import joblib

# After training your models with one-hot encoded data:
# rf_model = RandomForestClassifier().fit(X_encoded, y)
# tree_model = DecisionTreeClassifier().fit(X_encoded, y)

# Save models
joblib.dump(rf, "random_forest_model.pkl")
joblib.dump(tree_model, "decision_tree_model.pkl")

# Save column structure so we can align input data in Streamlit
joblib.dump(X_encoded.columns.tolist(), "feature_columns.pkl")

print("✅ Models and columns saved as .pkl")

# from google.colab import files

# files.download("random_forest_model.pkl")
# files.download("decision_tree_model.pkl")
# files.download("feature_columns.pkl")

# !pip install streamlit
# !pip install pyngrok

# from pyngrok import ngrok

# # Kill any previous tunnels
# ngrok.kill()

# # Run streamlit in the background
# !streamlit run flipkart_ui.py &

# # Create a tunnel to the Streamlit app
# public_url = ngrok.connect(port=8501)
# print("Streamlit app is live at:", public_url)

"""## Conclusion & Future Work

Conclusion:
- Most customers are satisfied (CSAT 4–5), but some categories, channels, and agents contribute to lower satisfaction.
- Sentiment polarity from customer remarks strongly correlates with CSAT scores.
- Machine learning models can effectively predict dissatisfaction, helping Flipkart take early action.

Recommendations:
- Provide training to underperforming agents based on CSAT trends.
- Improve processes in low-scoring issue categories (e.g., Returns, Delivery delays).
- Enhance support quality in channels with lower satisfaction.
- Use sentiment detection as an early alert system for customer dissatisfaction.

Future Work:
- Deploy a real-time dashboard to monitor CSAT predictions and sentiment alerts.
- Include additional features such as resolution time, agent workload, or product ratings.
- Conduct A/B tests to evaluate the impact of support process improvements.
"""

